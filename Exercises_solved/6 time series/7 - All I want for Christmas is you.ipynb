{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# All I want for Christmas is...\n",
    "\n",
    "[Link to kaggle notebook](https://www.kaggle.com/code/davidandressanchez/all-i-want-for-christmas-is-you)\n",
    "[Original article](https://mlpills.substack.com/p/issue-40-all-i-want-for-christmas)\n",
    "\n",
    "Welcome to a Christmas Special issue! Numerous countries across the globe gear up for Christmas celebrations, and what better way to celebrate it than with a festive Data Science project?\n",
    "\n",
    "Letâ€™s forecast the popularity of the \"All I Want for Christmas\" search by Mariah Carey on YouTube in the upcoming weeks.\n",
    "\n",
    "We can get the data from [google trends](https://trends.google.com/trends/explore?date=all_2008&gprop=youtube&q=%2Fm%2F05zrc5&hl=en-GB). The data included with this notebook has been updated in November 2024. Data before 2018 was deleted as data collection wasn't really working at Google yet (apparently)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-20T17:30:36.687666Z",
     "iopub.status.busy": "2023-12-20T17:30:36.687102Z",
     "iopub.status.idle": "2023-12-20T17:30:36.695604Z",
     "shell.execute_reply": "2023-12-20T17:30:36.693883Z",
     "shell.execute_reply.started": "2023-12-20T17:30:36.687625Z"
    }
   },
   "source": [
    "## Data cleaning\n",
    "\n",
    "First import the data. It's a simple CSV that pandas can handle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-12-21T10:01:26.947060Z",
     "iopub.status.busy": "2023-12-21T10:01:26.946617Z",
     "iopub.status.idle": "2023-12-21T10:01:26.959096Z",
     "shell.execute_reply": "2023-12-21T10:01:26.957759Z",
     "shell.execute_reply.started": "2023-12-21T10:01:26.947017Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Read dataset\n",
    "df = pd.read_csv('../files/multiTimeline.csv', header=0)\n",
    "\n",
    "# Rename columns\n",
    "df.columns = ['week', 'popularity']\n",
    "\n",
    "# Inspect data\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data looks good, but below 1000 views is stored in a non-numerical form. We'll remove the non-numeric values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-21T10:01:27.729049Z",
     "iopub.status.busy": "2023-12-21T10:01:27.728598Z",
     "iopub.status.idle": "2023-12-21T10:01:27.744988Z",
     "shell.execute_reply": "2023-12-21T10:01:27.743391Z",
     "shell.execute_reply.started": "2023-12-21T10:01:27.729012Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#DELETE\n",
    "df.popularity = df.popularity.replace('<1', 0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check for missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-21T10:01:28.240438Z",
     "iopub.status.busy": "2023-12-21T10:01:28.240028Z",
     "iopub.status.idle": "2023-12-21T10:01:28.250719Z",
     "shell.execute_reply": "2023-12-21T10:01:28.249375Z",
     "shell.execute_reply.started": "2023-12-21T10:01:28.240405Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#DELETE\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "None, great! Now fix the data types (if needed)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-21T10:01:28.688086Z",
     "iopub.status.busy": "2023-12-21T10:01:28.687624Z",
     "iopub.status.idle": "2023-12-21T10:01:28.697522Z",
     "shell.execute_reply": "2023-12-21T10:01:28.696125Z",
     "shell.execute_reply.started": "2023-12-21T10:01:28.688050Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#DELETE\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both are objects where popularity should be an int and week should be a date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-21T10:01:28.949061Z",
     "iopub.status.busy": "2023-12-21T10:01:28.948605Z",
     "iopub.status.idle": "2023-12-21T10:01:28.957235Z",
     "shell.execute_reply": "2023-12-21T10:01:28.955924Z",
     "shell.execute_reply.started": "2023-12-21T10:01:28.949025Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#DELETE\n",
    "df['week'] = pd.to_datetime(df['week'], format='%Y-%m-%d')\n",
    "df['popularity'] = df['popularity'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize data\n",
    "\n",
    "Is this a good song to be predicting on?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-21T10:04:00.371854Z",
     "iopub.status.busy": "2023-12-21T10:04:00.371439Z",
     "iopub.status.idle": "2023-12-21T10:04:00.724435Z",
     "shell.execute_reply": "2023-12-21T10:04:00.723076Z",
     "shell.execute_reply.started": "2023-12-21T10:04:00.371822Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#DELETE\n",
    "df.popularity.plot(figsize=(12, 5))\n",
    "plt.grid(True, alpha=0.5)\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Popularity')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The model\n",
    "\n",
    "Install and import SARIMA library. Arima is a good choice here because there is a definite seasonal part in the data. The downside is Arima has quite a lot of parameters that need to be set correctly, but autoarima fixes that for us.\n",
    "\n",
    "We'll start by renaming the columns in the way that autoarime likes them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-21T07:21:12.341494Z",
     "iopub.status.busy": "2023-12-21T07:21:12.341085Z",
     "iopub.status.idle": "2023-12-21T07:21:31.400982Z",
     "shell.execute_reply": "2023-12-21T07:21:31.399600Z",
     "shell.execute_reply.started": "2023-12-21T07:21:12.341461Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#DELETE\n",
    "from statsforecast import StatsForecast\n",
    "from statsforecast.models import AutoARIMA\n",
    "\n",
    "# Load and prepare the AirPassengers dataset\n",
    "df.rename(columns={'week': 'ds', 'popularity': 'y'}, inplace=True)\n",
    "\n",
    "# df['week'].rename('ds')\n",
    "\n",
    "# df['popularity'].rename('y')\n",
    "df['unique_id'] = 'song'\n",
    "\n",
    "# Keep only required columns\n",
    "df = df[['unique_id', 'ds', 'y']]\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the data... Use one year (52 weeks) as testing-data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-21T08:55:50.778788Z",
     "iopub.status.busy": "2023-12-21T08:55:50.778331Z",
     "iopub.status.idle": "2023-12-21T08:55:50.785238Z",
     "shell.execute_reply": "2023-12-21T08:55:50.784015Z",
     "shell.execute_reply.started": "2023-12-21T08:55:50.778754Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#DELETE\n",
    "# Split: last 52 weeks for testing\n",
    "h = 52\n",
    "df_train = df[:-h].copy()\n",
    "df_test = df[-h:].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Draw a graph of the split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-21T10:07:48.084786Z",
     "iopub.status.busy": "2023-12-21T10:07:48.084380Z",
     "iopub.status.idle": "2023-12-21T10:07:48.476175Z",
     "shell.execute_reply": "2023-12-21T10:07:48.475028Z",
     "shell.execute_reply.started": "2023-12-21T10:07:48.084754Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#DELETE\n",
    "ax = df_train.y.plot(figsize=(12, 5))\n",
    "df_test.y.plot(ax=ax)\n",
    "plt.grid(True, alpha=0.5)\n",
    "plt.legend(['Train set', 'Test set'])\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Popularity')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train your model with the train set\n",
    "\n",
    "We have weekly data. From the previous graph we can observe annual seasonality. Since a year has 52 weeks, we will select the seasonal period `m` as 52. We'll determine the frequency of the data automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-21T08:55:52.125467Z",
     "iopub.status.busy": "2023-12-21T08:55:52.124307Z",
     "iopub.status.idle": "2023-12-21T09:19:37.857034Z",
     "shell.execute_reply": "2023-12-21T09:19:37.855478Z",
     "shell.execute_reply.started": "2023-12-21T08:55:52.125421Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#DELETE\n",
    "# Fit AutoARIMA on training set\n",
    "freq = pd.infer_freq(df_train['ds'])\n",
    "\n",
    "sf = StatsForecast(\n",
    "    models=[AutoARIMA(season_length=52)],\n",
    "    freq=freq,\n",
    "    n_jobs=1\n",
    ")\n",
    "\n",
    "sf.fit(df_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make predictions and compare to test set\n",
    "\n",
    "We'll predict 52 weeks of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-21T10:12:18.738976Z",
     "iopub.status.busy": "2023-12-21T10:12:18.738545Z",
     "iopub.status.idle": "2023-12-21T10:12:18.814453Z",
     "shell.execute_reply": "2023-12-21T10:12:18.812641Z",
     "shell.execute_reply.started": "2023-12-21T10:12:18.738928Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#DELETE\n",
    "# Make predictions\n",
    "predictions = sf.predict(h=52)\n",
    "predictions.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"predictions\" is a dataframe with an index start at 0. Our test-data is a dataframe with an index starting 283, because there were a bunch of records before this data when we splitted it.\n",
    "\n",
    "We can fix this by resetting the index on df_test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DELETE\n",
    "df_test.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And then draw a graph of df_test vs predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-21T10:16:55.828863Z",
     "iopub.status.busy": "2023-12-21T10:16:55.828431Z",
     "iopub.status.idle": "2023-12-21T10:16:56.174842Z",
     "shell.execute_reply": "2023-12-21T10:16:56.173632Z",
     "shell.execute_reply.started": "2023-12-21T10:16:55.828830Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#DELETE\n",
    "ax = df_test.y.plot(figsize=(12, 5))\n",
    "predictions.AutoARIMA.plot(ax=ax)\n",
    "plt.grid(True, alpha=0.5)\n",
    "plt.legend(['Test set', 'Predictions'])\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Popularity')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like an ok model. That means our pipeline to get here was ok, so we'll rebuild that pipeline but this time use **all** of the data, not leaving a test-set behind. That is the model we can then use to predict actual data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the final model with all data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-21T10:18:13.049435Z",
     "iopub.status.busy": "2023-12-21T10:18:13.048907Z",
     "iopub.status.idle": "2023-12-21T10:31:43.738577Z",
     "shell.execute_reply": "2023-12-21T10:31:43.737282Z",
     "shell.execute_reply.started": "2023-12-21T10:18:13.049398Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#DELETE\n",
    "# Fit AutoARIMA on training set\n",
    "freq = pd.infer_freq(df['ds'])\n",
    "\n",
    "sf = StatsForecast(\n",
    "    models=[AutoARIMA(season_length=52)],\n",
    "    freq=freq,\n",
    "    n_jobs=1\n",
    ")\n",
    "\n",
    "sf.fit(df)\n",
    "\n",
    "# Make predictions\n",
    "predictions = sf.predict(h=52)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To show this on a graph decently we need to reset the index of \"predictions\" so it starts at the max index of df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DELETE\n",
    "max_index = df.index.max()\n",
    "predictions.index = range(max_index + 1, max_index + 1 + len(predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now show how popular the song will be next Christmas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-21T10:32:05.939088Z",
     "iopub.status.busy": "2023-12-21T10:32:05.938649Z",
     "iopub.status.idle": "2023-12-21T10:32:06.333328Z",
     "shell.execute_reply": "2023-12-21T10:32:06.332029Z",
     "shell.execute_reply.started": "2023-12-21T10:32:05.939053Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#DELETE\n",
    "ax = df.y.plot(figsize=(12, 5))\n",
    "predictions.AutoARIMA.plot(ax=ax)\n",
    "plt.grid(True, alpha=0.5)\n",
    "plt.legend(['Historical data', 'Predictions'])\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Popularity')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Another song?\n",
    "\n",
    "Now try with another song. Try \"always look on the bright side of life\" which may or may not be related to easter. Or maybe dead metal songs have a popularity just before Graspop, the metal-festival in Dessel?"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 4199874,
     "sourceId": 7249118,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30626,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "venv (3.12.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
