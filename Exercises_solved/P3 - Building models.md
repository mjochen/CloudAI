# Building models

The previous part ended with a single notebook that would prepare your data for predicting. Next is building a model and actually predicting something. This is a phase that you can do individually.

For both Titanic and the crop-dataset you need at least a model using **AWS** and another model that **PyCaret** suggested. Thirdly you'll also need a model that you manually implemented, along with the reason you choose this exact model. Alse, the teammember doing AWS on one dataset can not do it again on the other dataset. (Same for PyCaret).

When the models are done, gather the metrics that describe these models. Export them (CSV, Pickle, ...) and put them together in a single notebook. There you'll do a deep analysis on which of the models performed better.