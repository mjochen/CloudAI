{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling residuals on university rankings\n",
    "\n",
    "We'll try to apply the principles we saw in the diamonds-example to [this](https://www.kaggle.com/datasets/alitaqi000/world-university-rankings-2023) dataset. And to make it a competition or anything, but let's see who has the most influence on the ranking of a university: the rate of international students or the teaching score!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "df=pd.read_csv(\"files/World University Rankings 2023.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the purpose of this exercise, we'll only be looking at countries with a lot of universities in them. Sort by descending amount of universities and keep only those rows from the top 10 countries. (Hint, the 11th country, Pakistan, has 55 universities.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DELETE\n",
    "sub_df = df[df.groupby('Location').Location.transform('count')>55].copy()\n",
    "sub_df.head()\n",
    "\n",
    "sub_df.Location.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now do a boxplot for \"Teaching score\", our goal metric, split by country."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(data=sub_df, x='Location', y='OverAll Score')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Doesn't look like much, does it? A number of our metrics are numbers that are stored as objects. Compare which ones by looking at the data and the datatypes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DELETE\n",
    "\n",
    "print(sub_df.head())\n",
    "print(sub_df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An overview:\n",
    "- Name of University             , object: Ok!\n",
    "- Location                       , object: Ok!\n",
    "- No of student                  , object: Wrong\n",
    "- No of student per staff       , float64: Ok!\n",
    "- International Student          , object: Wrong\n",
    "- Female:Male Ratio              , object: Wrong\n",
    "- OverAll Score                  , object: Wrong\n",
    "- Teaching Score                , float64: Ok!\n",
    "- Research Score                , float64: Ok!\n",
    "- Citations Score               , float64: Ok!\n",
    "- Industry Income Score         , float64: Ok!\n",
    "- International Outlook Score   , float64: Ok!\n",
    "\n",
    "Fix the wrong ones. Do you also feel the [lambda](https://www.geeksforgeeks.org/applying-lambda-functions-to-pandas-dataframe/)-vibe in this one?\n",
    "\n",
    "(Challenges: nan-values, OverAll score sometimes contains \"10.5-18.3\" or something like that and the \"-\" isn't a normal \"-\", ratio has to be split and divided female/male, but there is an all female-college.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DELETE\n",
    "\n",
    "def ratio_to_nr(ratio):\n",
    "    if isinstance(ratio, float) or ratio.find(\":\") == -1:\n",
    "        return 0\n",
    "    data = str(ratio).split(\" : \")\n",
    "    if data[1] == \"0\":\n",
    "        return 1\n",
    "    return int(data[0])/int(data[1])\n",
    "\n",
    "def overall_score_fix(score):\n",
    "    if isinstance(score, float):\n",
    "        return score\n",
    "    \n",
    "    if score.find(\"–\") == -1:\n",
    "        return float(score)\n",
    "    \n",
    "    data = score.split(\"–\")\n",
    "    data = [ float(x) for x in data]\n",
    "    return (data[0] + data[1])/2\n",
    "\n",
    "sub_df[\"No of student\"] = sub_df[\"No of student\"].str.replace(\",\",\"\").astype(int)\n",
    "sub_df[\"International Student\"] = sub_df[\"International Student\"].apply(lambda x: 0 if x == \"%\" else float(x.replace(\"%\",\"\")))\n",
    "sub_df[\"Female:Male Ratio\"] = sub_df[\"Female:Male Ratio\"].apply(ratio_to_nr)\n",
    "sub_df[\"OverAll Score\"] = sub_df[\"OverAll Score\"].apply(overall_score_fix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above code-block can only be run once, since it stores the cleaned values in the fields itself.\n",
    "\n",
    "But we were doing a boxplot!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(data=sub_df, x='Location', y='OverAll Score')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There seems to be some influence. What other metrics are important? Try a correlation matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DELETE\n",
    "\n",
    "# plot a correlation matrix of sub_df\n",
    "corr = sub_df.corr(numeric_only=True)\n",
    "sns.heatmap(corr, annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are trying to maximize the OverAll Score, so if we look at that line and do some creative copy-pasting in paint, we get the following image.\n",
    "\n",
    "![](files/2023-09-14-15-24-10.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now analyze this data. What is the influence of the different columns?\n",
    "\n",
    "(The following is a code-block, but we expect only text, the sort of which you'll also be expected to be able to produce on the exam.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DELETE\n",
    "\n",
    "# An overview:\n",
    "# - No of student: 0,069, small positive correlation, can be neglected\n",
    "# - No of student per staff: -0.24, reasonable negative correlation. Negative so more staff per student means a better university\n",
    "# - International Student: 0,59, good positive correlation\n",
    "# - Female:Male Ratio: 0,096, small positive correlation, can be neglected. Note: higher number means more female students, so more female students mean a better university, although not statistically significant\n",
    "# - OverAll Score: 1, because the same value\n",
    "# - Teaching Score: 0,85, high positive correlation\n",
    "# - Research Score: 0,88, high positive correlation\n",
    "# - Citations Score: 0,85, high positive correlation\n",
    "# - Industry Income Score: 0,37 reasonable positive correlation\n",
    "# - International Outlook Score: 0,65, good positive correlation\n",
    "\n",
    "# concluding: the influence of teaching score, research score and citations score is very big. This should be modelled first."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also, copy-pasting in paint? Really? Show all values from the correlation matrix for OverAll Score order from high to low."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DELETE\n",
    "\n",
    "corr[\"OverAll Score\"].sort_values(ascending=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the teaching score vs the overall score in a scatter plot. Add the percentage of international students as a color."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DELETE\n",
    "\n",
    "# Draw a scatter plot of overall score vs teaching score. Add international student as color.\n",
    "\n",
    "# plt.scatter(sub_df[\"OverAll Score\"], sub_df[\"Teaching Score\"])\n",
    "sns.scatterplot(data=sub_df, x=\"OverAll Score\", y=\"Teaching Score\", hue=\"International Student\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dark dots (high number of international students) occur more on the right side of the plot, but some also appear on the left. We know there is a positive effect, but how big is it? To understand that we have to remove the influence of the Teaching score.\n",
    "\n",
    "We'll assume the influence of teaching score on overall score is linear. No need to do a log this time.\n",
    "\n",
    "Also, to make the linear regression model work we'll need to delete all na-values. Wish we would have done that before converting al the datatypes, it would have made our lives a lot easier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(sub_df.count())\n",
    "sub_df.dropna(inplace=True)\n",
    "# print(sub_df.count())\n",
    "\n",
    "from sklearn import datasets, linear_model\n",
    "\n",
    "x = sub_df[\"Teaching Score\"].values.reshape(-1, 1)\n",
    "y = sub_df[\"OverAll Score\"].values.reshape(-1, 1)\n",
    "\n",
    "regr = linear_model.LinearRegression()\n",
    "model = regr.fit(x, y)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12,6))\n",
    "\n",
    "sub_df.plot(kind='scatter', x=\"Teaching Score\", y=\"OverAll Score\", grid=True,fontsize=10, ax=ax,  figsize=(12, 6), alpha=0.1)\n",
    "plt.plot(x, regr.predict(x), color='red')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maybe print the parameters for the regression-line?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"a= {model.coef_[0][0]}, b= {model.intercept_[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And there is our linear model. Now we use this to predict the values for every weight. Once we have this predicted weight, we use it to calculate the residuals (or the error) for every actual value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_df['overall_score_predicted'] = model.predict(sub_df[\"Teaching Score\"].values.reshape(-1, 1))\n",
    "sub_df['overall_score_residuals'] = sub_df[\"OverAll Score\"] - sub_df['overall_score_predicted']\n",
    "\n",
    "# df.head()\n",
    "sub_df.plot(kind='scatter', x=\"Teaching Score\", y=\"overall_score_residuals\", grid=True,fontsize=10, figsize=(12, 6), alpha=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we have here is a plot of teaching score vs the residuals of the overall score. These residuals imply that the teaching score has no predictive value anymore and that is actually the case: the data is almost random.\n",
    "\n",
    "Well, not quite. There are still some lines left because the research score and the citations score are still in there. But if we plot the residuals of the the overall score vs the international students, what do we get?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_df.plot(kind='scatter', y=\"International Student\", x=\"overall_score_residuals\", grid=True,fontsize=10, figsize=(12, 6), alpha=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that:\n",
    "- Most schools have a low percentage of international students (< 20). They have both positive and negative residuals, so both bad and good scores.\n",
    "- Above 20% international students we don't see many below 0 residuals anymore. This means that there is indeed a trend that more international students mean better schools.\n",
    "\n",
    "But was all this necessary? Couldn't we have just made the same plot with the original data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DELETE\n",
    "\n",
    "sub_df.plot(kind='scatter', y=\"International Student\", x=\"OverAll Score\", grid=True,fontsize=10, figsize=(12, 6), alpha=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The trend is indeed there, but less explicit than after applying the model. This should become even clearer when you remove the research and the citations score from the residuals."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
