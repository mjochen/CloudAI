{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bike highways - revisit in AWS\n",
    "\n",
    "We've let PyCaret do it's magic, but can we also get these results ourselves?\n",
    "\n",
    "We'll load the data for the same point locally and prepare it to be used on AWS (as we saw in the lab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('files/bike_counters_data/Measured data-nl-Geel_FMN GV 21 Geel.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AWS tells us to:\n",
    "\n",
    "- Removes instances with missing values\n",
    "- Sets the index to the InvoiceDate feature\n",
    "- Only keeps instances that are from the United Kingdom\n",
    "- Only keeps instances that use the target stock code (21232)\n",
    "- Keeps instances where the price is greater than 0\n",
    "\n",
    "(On the other dataset. Translate to our dataset!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DELETE\n",
    "\n",
    "# Removes instances with missing values -> not needed\n",
    "df.dropna()\n",
    "\n",
    "# Sets the index to the InvoiceDate feature -> first combine the date, then set it as index\n",
    "df[\"date_time\"] = df[\"Datum\"] + \" \" + df[\"Tijd\"]\n",
    "df[\"date_time\"] = pd.to_datetime(df[\"date_time\"])\n",
    "df = df.set_index(\"date_time\")\n",
    "df.head()\n",
    "\n",
    "# Only keeps instances that are from the United Kingdom -> ignore\n",
    "# Only keeps instances that use the target stock code (21232) -> ignore\n",
    "# Keeps instances where the price is greater than 0 -> don't delete hours on which there were no cyclists! A price of 0 is wrong, 0 cyclists is the correct nr of cyclists\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next part: generating training and test data frames. AWS says the following:\n",
    "\n",
    "- Splits the data into a time series DataFrame and a related time series DataFrame.\n",
    "- Downsamples the data from multiple sales entries per day into a single daily value. The **Quantity** column is summed, and the mean is used for the **Price** column.\n",
    "- Splits the DataFrames into a training set that contains data from January 2010–October 2010, and a test set that contains data from November 2010–December 2010\n",
    "\n",
    "Don't do it all at once. First resample to a daily value and then plot your data. That makes it easier to see which timespan to use for testing and training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DELETE\n",
    "\n",
    "# Splits the data into a time series DataFrame and a related time series DataFrame.\n",
    "df_time_series = df[[\"Aantal fietsers\"]]\n",
    "# df_time_series.head()\n",
    "\n",
    "# Downsamples the data from multiple sales entries per day into a single daily value. The **Quantity** column is summed, and the mean is used for the **Price** column.\n",
    "# We'll resample to a daily value, summing the nr of cyclists\n",
    "df_time_series = df_time_series.resample('D').sum().reset_index().set_index(['date_time'])\n",
    "# df_time_series.head()\n",
    "df_time_series.plot()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note the lines that are stuck to the bottom? Those are days on which the meter was broken. We should delete these as they're not readings but errors. Also note that the error-values aren't always zero, around January 2021 there were some way to small values. Filter them out and plot again..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_time_series[ df_time_series[\"Aantal fietsers\"] == df_time_series[\"Aantal fietsers\"].max() ]\n",
    "\n",
    "# df_time_series.loc[ df_time_series[\"Aantal fietsers\"] <= 100 ].plot -> arbirtrary threshold, check which works by trial and error.\n",
    "\n",
    "df_time_series = df_time_series.loc[ df_time_series[\"Aantal fietsers\"] >= 30 ]\n",
    "df_time_series.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See how the flat lines have been replaced by diagonal lines?\n",
    "\n",
    "![](files/2023-10-09-15-51-09.png)\n",
    "\n",
    "There aren't any values there, but because we drew a line graph the plot needs to be filled in. It therefore assumes a direct line between both values, but the model normally won't be bothered by it.\n",
    "\n",
    "But back to AWS! Next part: generating training and test data frames. We were left with:\n",
    "\n",
    "- Splits the DataFrames into a training set that contains data from January 2010–October 2010, and a test set that contains data from November 2010–December 2010"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DELETE\n",
    "\n",
    "df_time_series\n",
    "\n",
    "start_July_2022 = df_time_series[:'2022-07']\n",
    "August_2022_end = df_time_series['2022-08':]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next up is uploading to Amazon. It would be good to try this out in the AWS-canvas course and compare the results to PyCaret and our manual experimentations (from the next notebook)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
