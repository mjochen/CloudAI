{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear regression\n",
    "\n",
    "Linear regression is a statistical method used to establish a relationship between a dependent variable (also known as the response variable) and one or more independent variables (also known as the predictor variables). It assumes that the relationship between the variables is linear, meaning that the change in the response variable is directly proportional to the change in the predictor variables.\n",
    "\n",
    "The goal of linear regression is to fit a line that best explains the relationship between the variables, which can then be used to make predictions about the response variable. The line is estimated by minimizing the sum of the squared differences between the observed values of the response variable and the predicted values from the model.\n",
    "\n",
    "We'll be using it mainly as a way of explaining our data. We start out with the mpg-dataset, widely used in R (the programming language)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# When trying this notebook, you are using a virtual environment, no?\n",
    "# Because you should be.\n",
    "\n",
    "!pip install pandas\n",
    "!pip install matplotlib\n",
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load mpg.csv as a pandas dataframe\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "mpg = pd.read_csv('files/mpg.csv')\n",
    "mpg.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start out with a simple graph of engine displacement vs highway miles per gallon (displ vs hwy)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A scatterplot of displ vs hwy in mpg\n",
    "mpg.plot(kind='scatter', x=\"displ\", y=\"hwy\", grid=True,fontsize=10, figsize=(12, 6))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " In this graph we can already see a bit of a linear trendline (bigger engine means lower miles per gallon). But we want to quantify this, so we can draw a couple of random lines on the graph and see which is best.\n",
    "\n",
    " (https://stackoverflow.com/questions/39732288/pandas-how-to-plot-a-line-in-a-scatter-and-bring-it-to-the-back-front)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12,6))\n",
    "\n",
    "mpg.plot(kind='scatter', x=\"displ\", y=\"hwy\", grid=True,fontsize=10, ax=ax) \n",
    "\n",
    "# some predefined lines, as fully random would be really weird\n",
    "a = (-5, 5, 0.5, -4)\n",
    "b = (50, 0, 20, 35)\n",
    "\n",
    "# add to graph\n",
    "for i in range(len(a)):\n",
    "    line = np.linspace(min(mpg.displ), max(mpg.displ), 10)\n",
    "    x_line = (a[i] * line) + b[i]\n",
    "    ax.plot(line, x_line, zorder=-1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These lines are our model. When we have a displacement of 4 the blue line will predict a value of 30. You can calculate this using the values we used for a and b:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(a)):\n",
    "    predict = a[i] * 4 + b[i]\n",
    "    print(f\"a= {a[i]}, b= {b[i]}, predict= {predict}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But what line is better? The line needs to go down (blue and red), and red is better than blue but to low. What we need is a metric that objectively measures the 'goodness' of a line. For this we need the error. The error is the difference between the predicted value and the actual value.\n",
    "\n",
    "Let's calculate the error for the first car in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"actual= {mpg.hwy[0]}\")\n",
    "\n",
    "\n",
    "for i in range(len(a)):\n",
    "    predict = a[i] * 4 + b[i]\n",
    "    error = predict - mpg.hwy[0]\n",
    "    print(f\"a= {a[i]}, b= {b[i]}, predict= {predict}, error= {error}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see the error varies wildly and is quite large in some cases. (Which is normal as we are simply using random lines as a model.) But how do we use this error (or the combination of all errors for every line in our data) to check the model?\n",
    "\n",
    "There are a couple of options:\n",
    "\n",
    "* Simply add the errors: Some errors are positive, others are negative. This doesnâ€™t add up well.\n",
    "* Add the absolute value of the errors: Could work but we really want to penalize the big errors.\n",
    "* Mean squared error (MSE): We square all the errors and take the average (mean). This is our metric.\n",
    "* Root mean squared error (RMSE): the MSE, but we take the root of this value.\n",
    "\n",
    "The MSE is a good measure: squaring takes care of the sign of the error (or the error above or below the prediction-line), but the result we get is an error in \"miles per gallon squared\". This does not compare to the actual value in the dataset. We van fix this by taking the root of the value. Et voila: RMSE.\n",
    "\n",
    "![](files/2023-04-11-19-26-30.png)\n",
    "\n",
    "But let's calculate these errors for our four lines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function calculates the predicted value for every line we drew earlier (every model)\n",
    "def predict(x):\n",
    "    predictions = []\n",
    "    for i in range(len(a)):\n",
    "        predictions.append(a[i] * x + b[i])\n",
    "    return predictions\n",
    "\n",
    "# Go over data, add predicted values to dataframe\n",
    "mpg['pred1'], mpg['pred2'], mpg['pred3'], mpg['pred4'] = predict(mpg.displ)\n",
    "# mpg['predicted'] = mpg.displ.apply(predict)\n",
    "\n",
    "mpg.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare the RMSE-values:\n",
    "for i in range(len(a)):\n",
    "    rmse = np.sqrt(np.mean((mpg.hwy - mpg[f\"pred{i+1}\"])**2))\n",
    "    print(f\"a= {a[i]}, b= {b[i]}, RMSE= {rmse}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see the last line (the blue one) is the best, but it's still only a little bit better than the one just above, the green one. And that one even goes in the wrong direction (up in stead of down).\n",
    "\n",
    "You might have wandered if manually calulating the RMSE is really the only option. It isn't: https://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_squared_error.html\n",
    "\n",
    "You could now start tweaking a and b, trying to get the rmse as low as possible. Or you could use an existing toolkit, like the really good scikit-learn, to generate the best possible trendline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets, linear_model\n",
    "\n",
    "x = mpg.displ.values.reshape(-1, 1)\n",
    "y = mpg.hwy.values.reshape(-1, 1)\n",
    "\n",
    "regr = linear_model.LinearRegression()\n",
    "model = regr.fit(x, y)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12,6))\n",
    "\n",
    "mpg.plot(kind='scatter', x=\"displ\", y=\"hwy\", grid=True,fontsize=10, ax=ax) \n",
    "plt.plot(x, regr.predict(x), color='blue')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks a lot like our last line. But what were the values for A and B that were optimal? And what RMSE doe we have now? Note how we use the scikit-RMSE-calculator now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "print(f\"a= {model.coef_[0][0]}, b= {model.intercept_[0]}\")\n",
    "\n",
    "mpg['model_predicted'] = model.predict(mpg.displ.values.reshape(-1, 1))\n",
    "print(\"New RMSE:\", np.sqrt(mean_squared_error(mpg.hwy, mpg.model_predicted)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, our wild guess of -4 and 35 wasn't that bad. The RMSE we had, 4.513512476087207, was only a bit bigger than 3.819556631201452.\n",
    "\n",
    "Is this a bad RMSE? Well, we're predicting hwy which is between 12 and 44. When we guess a value it's on average 3.8 off the actual value, which comes down to more than 10% . That really isn't that good so when doing data science you should now keep on digging.\n",
    "\n",
    "Let's take a look at the residuals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpg['residuals'] = mpg['hwy'] - mpg['model_predicted']\n",
    "mpg.plot(kind='scatter', x=\"displ\", y=\"residuals\", grid=True,fontsize=10, figsize=(12, 6))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another plot is a density plot of the residuals. If it's a perfect gaussian distribution (the normal curve) than the model is equally perfect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpg.residuals.plot.density(grid=True,figsize=(12, 6))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And it isn't. There's a trail on the left (the bump from 10 on) that corresponds to the dots in the upper right corner of the scatterplot. This is data that is not behaving according to our model.\n",
    "\n",
    "* Is a linear regression the correct model?\n",
    "* Do I have to split up the data?\n",
    "\n",
    "The last one, if you remember the mpg-dataset, is actually true: if you calculate trends per type of vehicle (compact, minivan, suv, ... ) you'll get better results. In fact, the misbehaving dots are the 2seater-cars: sports cars with large engines and low weight giving them good miles per gallons. Any decent prediction will have to include this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# just quick lookups\n",
    "print(min(mpg.hwy), max(mpg.hwy))\n",
    "print(mpg[\"class\"].unique())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
