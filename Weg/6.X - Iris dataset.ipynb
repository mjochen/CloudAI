{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cf323287",
   "metadata": {},
   "source": [
    "Absolutely! Let's walk through an example where **cross-validation combined with grid search** helps improve the performance of a **Decision Tree classifier** by tuning its hyperparameters.\n",
    "\n",
    "---\n",
    "\n",
    "## üå≥ Why This Matters for Decision Trees\n",
    "\n",
    "Decision trees are **prone to overfitting**, especially when they are allowed to grow deep without constraint. Using **cross-validation + hyperparameter tuning**, we can find the **best depth and splitting strategy**, which can significantly improve **generalization**.\n",
    "\n",
    "---\n",
    "\n",
    "### ‚úÖ Full Example: Decision Tree with Grid Search and Cross-Validation\n",
    "\n",
    "We'll use the **Iris dataset** again to keep things simple, and tune:\n",
    "\n",
    "* `max_depth`: how deep the tree can grow\n",
    "* `min_samples_split`: minimum samples to split a node\n",
    "\n",
    "---\n",
    "\n",
    "#### üß™ Code Example\n",
    "\n",
    "```python\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Load the data\n",
    "X, y = load_iris(return_X_y=True)\n",
    "\n",
    "# Base model\n",
    "dtree = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# Define hyperparameter grid\n",
    "param_grid = {\n",
    "    'max_depth': [None, 2, 3, 4, 5],\n",
    "    'min_samples_split': [2, 5, 10]\n",
    "}\n",
    "\n",
    "# Set up grid search with 5-fold cross-validation\n",
    "grid_search = GridSearchCV(dtree, param_grid, cv=5)\n",
    "\n",
    "# Fit the model\n",
    "grid_search.fit(X, y)\n",
    "\n",
    "# Output results\n",
    "print(\"Best parameters:\", grid_search.best_params_)\n",
    "print(\"Best cross-validated accuracy:\", grid_search.best_score_)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### üìù Sample Output\n",
    "\n",
    "```\n",
    "Best parameters: {'max_depth': 3, 'min_samples_split': 2}\n",
    "Best cross-validated accuracy: 0.9733\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### üîç How This Helps\n",
    "\n",
    "| Approach             | Description                                 | Accuracy |\n",
    "| -------------------- | ------------------------------------------- | -------- |\n",
    "| Default DecisionTree | Overfits if `max_depth` is too large        | \\~0.93   |\n",
    "| Tuned via CV         | Better generalization (e.g., `max_depth=3`) | \\~0.97   |\n",
    "\n",
    "By evaluating multiple combinations and averaging across folds, we:\n",
    "\n",
    "* **Avoid overfitting** by choosing a more constrained tree\n",
    "* **Improve test accuracy**\n",
    "* Ensure the model is **robust to small fluctuations in the data**\n",
    "\n",
    "---\n",
    "\n",
    "Would you like to visualize the decision tree or see training-vs-validation accuracy for different depths?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c088f0ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X, y = load_iris(return_X_y=True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b3916087",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'max_depth': 3, 'min_samples_split': 2}\n",
      "Best cross-validated accuracy: 0.9733333333333334\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Base model\n",
    "dtree = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# Define hyperparameter grid\n",
    "param_grid = {\n",
    "    'max_depth': [None, 2, 3, 4, 5],\n",
    "    'min_samples_split': [2, 5, 10]\n",
    "}\n",
    "\n",
    "# Set up grid search with 5-fold cross-validation\n",
    "grid_search = GridSearchCV(dtree, param_grid, cv=5)\n",
    "\n",
    "# Fit the model\n",
    "grid_search.fit(X, y)\n",
    "\n",
    "# Output results\n",
    "print(\"Best parameters:\", grid_search.best_params_)\n",
    "print(\"Best cross-validated accuracy:\", grid_search.best_score_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dc6fac7",
   "metadata": {},
   "source": [
    "Support vector machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1f052fb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9333333333333333\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Load data\n",
    "X, y = datasets.load_iris(return_X_y=True)\n",
    "\n",
    "# Train/test split\n",
    "\n",
    "\n",
    "# Train SVM classifier\n",
    "clf = SVC(kernel='linear')  # try 'rbf', 'poly' too\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict\n",
    "print(clf.score(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e176555e",
   "metadata": {},
   "source": [
    "kNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b1666c5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9333333333333333\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Load data\n",
    "X, y = load_iris(return_X_y=True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# Train k-NN with k=3\n",
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# Predict and score\n",
    "print(knn.score(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2a73cfe",
   "metadata": {},
   "source": [
    "Naive bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dd16ade5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# Load data\n",
    "X, y = load_iris(return_X_y=True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# Train Naive Bayes\n",
    "nb = GaussianNB()\n",
    "nb.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "print(nb.score(X_test, y_test))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
