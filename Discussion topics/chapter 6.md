# Discussion topics chapter 6 - Time series

1. What is the difference between time series data and non-time-series data?
1. Why can't 'normal' models be applied to time series data?
1. How can trends and seasonality in time series data affect forecasting accuracy?
1. Why is it inappropriate to randomly shuffle data when splitting time series into train and test sets?
1. How do different methods of filling missing values (e.g., forward fill, interpolation, ...) impact model performance?
1. What are the benefits and drawbacks of smoothing time series data before modeling?
1. Why is RMSE a suitable metric for evaluating time series models, and when might it be misleading?
1. How do sparse and dense datasets differ in structure and use cases?
1. When would you choose to convert sparse data into a dense format, and what are the trade-offs?
1. What is stationarity in time series modeling, and how can you test for it?
1. How does stability differ from stationarity?
1. What does first-order differencing achieve, and why is it useful for models like ARIMA?
1. What are inverse transformations and when do we need them?
1. How does autocorrelation help identify seasonality in time series data?
1. What insights can you gain from an autocorrelation plot, and how do you interpret spikes?
1. How do ARIMA, DeepAR+, ETS, NPTS, and Prophet differ in their approach to time series forecasting?
1. Why might you choose a non-parametric model like DeepAR+ or NPTS over parametric ones?
1. What are the strengths and limitations of Prophet, and in what scenarios is it most effective?
1. How does the choice of model depend on the characteristics of your time series data (e.g., missing values, seasonality, multivariate vs univariate)?