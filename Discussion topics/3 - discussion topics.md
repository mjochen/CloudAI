# Discussion topics part 2

## The powerpoint and exercises


1. How do you determine if a model is good? What metrics and methods can you use to evaluate its performance?
1. Why is it important for a model to generalize to unseen data? What are the risks of a model that doesn't generalize well?
1. Why do we split the dataset into training and test sets? How does this help in evaluating the model's performance?
1. What does RMSE (Root Mean Square Error) tell us about a model's performance? Why is it important to compare RMSE on both training and test datasets?
1. What are the signs of overfitting and underfitting in a model? How can you address these issues?
1. How does polynomial regression differ from linear regression? What are the challenges associated with using higher-order polynomials?
1. What is the bias-variance tradeoff? How do you find the right balance between bias and variance in a model?
1. How can the sensitivity to the train/test split affect model performance? What strategies can you use to mitigate this sensitivity?
1. How do you model more complex patterns in data? What techniques can be used to capture these patterns effectively?
1. What common issues can arise in the data you receive? How can you address problems like outliers, missing values, and bias?
1. How do outliers impact your data analysis and model performance? What are some strategies for handling outliers?
1. Why doesn't the Z-score matter in a column that is used in one hot encoding?
1. What are the differences between nominal and ordinal data? How do you handle categorical data in machine learning models?
1. What are the different strategies for handling missing values in a dataset? When might you choose one method over another?
1. What are the different types of bias that can affect your data and models? How can you mitigate these biases?
1. Why is scaling important in data preprocessing? What are the differences between min-max scaling and standardization?

