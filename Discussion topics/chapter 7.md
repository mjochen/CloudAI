# Discussion topics chapter 7 - Unsupervised learning

1. How does unsupervised learning differ from supervised learning in terms of goals and outcomes?
1. Why is clustering considered a form of pattern recognition rather than prediction?
1. What challenges arise when clustering data in more than two dimensions?
1. How does the KMeans algorithm determine which data points belong to which cluster?
1. What does the concept of "inference" mean in the context of unsupervised learning?
1. Why might a clustering model struggle to correctly group similar data, such as in the Iris dataset?
1. How can inertia help determine the optimal number of clusters in a dataset?
1. What does the "elbow" in an inertia plot represent, and how should it guide model selection?
1. Why does scaling affect the performance of clustering algorithms like KMeans?
1. What are the consequences of using unscaled data in distance-based clustering?
1. How do normalization and standardization differ, and when should each be used?
1. Why is it important to apply the same scaling parameters to new data during inference?
1. How can clustering be used to support supervised learning tasks?
1. What are the limitations of unsupervised learning when it comes to interpreting results?
1. How does scaling impact the interpretability and reliability of clustering outcomes?