{"cells": [{"cell_type": "markdown", "id": "c6911869", "metadata": {}, "source": ["# Winetrees\n", "\n", "This notebook works with the wine-dataset and hopes to show you the benefits of k-fold and gridsearch.\n", "\n", "Let's begin by importing the data"]}, {"cell_type": "code", "execution_count": 1, "id": "cde31c55", "metadata": {}, "outputs": [], "source": ["from sklearn.datasets import load_wine\n", "X, y = load_wine(return_X_y=True)"]}, {"cell_type": "code", "execution_count": 4, "id": "589563b1", "metadata": {}, "outputs": [], "source": ["import pandas as pd\n", "\n", "# Convert X to DataFrame\n", "df_wine = pd.DataFrame(X)\n", "\n", "# Add y as a new column named \"type\"\n", "df_wine['type'] = y\n", "\n", "df_wine.head()\n", "\n", "df_wine.to_csv('wine.csv', index=False)"]}, {"cell_type": "markdown", "id": "0a80a1ca", "metadata": {}, "source": ["## Data exploration\n", "\n", "Get the info and the size of the wine-dataset."]}, {"cell_type": "code", "execution_count": null, "id": "bae5b85a", "metadata": {}, "outputs": [], "source": ["# Up to you!\n", "\n"]}, {"cell_type": "markdown", "id": "014ec944", "metadata": {}, "source": ["Now some data-exploring. Create three different graphs about your dataset. Let's say:\n", "\n", "- A histogram of the first feature\n", "- All boxplots\n", "- Correlation matrix"]}, {"cell_type": "code", "execution_count": null, "id": "dfea08e8", "metadata": {}, "outputs": [], "source": ["# Up to you!\n", "\n"]}, {"cell_type": "markdown", "id": "2cc97e20", "metadata": {}, "source": ["## Model creation\n", "\n", "Normally we'd now split the dataset in a train and test set, but the dataset is very small. Make a decision tree of max 3 branches deep, using the random state of 42. Also setup KFold with 5 splits and shuffle."]}, {"cell_type": "code", "execution_count": null, "id": "d3194f37", "metadata": {}, "outputs": [], "source": ["# Up to you!\n", "\n"]}, {"cell_type": "markdown", "id": "97b8f8c7", "metadata": {}, "source": ["Now go over all the splits in the KFold-object you just made and store the accuracies in a list. Print the list and the mean of the list."]}, {"cell_type": "code", "execution_count": null, "id": "8ac43f59", "metadata": {}, "outputs": [], "source": ["# Up to you!\n", "\n"]}, {"cell_type": "markdown", "id": "359c77ca", "metadata": {}, "source": ["Now play around with the tree depth and number of folds a bit. The idea is to get the highest possible average accuracy.\n", "\n", "But wait, you may think, why not take the fold with the highest accuracy? Because this every fold is only trained on part of the dataset. If you were to take that particular model you'd be overfitting on that particular fold.\n", "\n", "That's why we are playing around with the numbers. What we want to achieve is **hyper parameter tuning**, and the hyper parameter is the depth of the tree. Too high and we're overfitting, not high enough and we'll have a bad fit. By trying out all the numbers by hand we can see where the number is best.\n", "\n", "And the k-fold helps us doing this without splitting the data in three parts (train, test, validation), because we don't have enough data for that (only 176 rows).\n", "\n", "Another thing nagging in your mind right now: Why am I changing numbers manually and test them? Can't we automate that? And yes, we can."]}, {"cell_type": "markdown", "id": "7a5e978e", "metadata": {}, "source": ["## Gridsearch\n", "\n", "Gridsearch is a way to automate hyper parameter tuning. We can input a number of parameters in which we want to test a model.\n", "\n", "We'll be using it to tune another Decision tree parameter: min_samples_split. This parameter means \"Don't split a node unless it has at least this many samples.\". If we allow the model to keep on splitting nodes we'll end up with a lot of leaves in our tree, which means we're probably overfitting. Keeping it to big will lead to underfitting.\n", "\n", "We'll try max_depths of 2, 3, 4, 5, 6 and min_samples_splits of 2, 4, 6, 10.\n"]}, {"cell_type": "code", "execution_count": null, "id": "1aa7db11", "metadata": {}, "outputs": [], "source": ["# Up to you!\n", "\n"]}, {"cell_type": "markdown", "id": "d367d795", "metadata": {}, "source": ["What happened now is that the grid_search made a grid 20 (=5x4) squares, combining all max_depths and all min_samples_splits. From this grid it deduced that a max_depth of 4 and a min_samples_split of 6 will work best.\n", "\n", "Try to show the full grid as well."]}, {"cell_type": "code", "execution_count": null, "id": "110def31", "metadata": {}, "outputs": [], "source": ["# Up to you!\n", "\n"]}, {"cell_type": "markdown", "id": "87cf77f4", "metadata": {}, "source": ["In a heatmap even?"]}, {"cell_type": "code", "execution_count": null, "id": "c9de59f7", "metadata": {}, "outputs": [], "source": ["# Up to you!\n", "\n"]}], "metadata": {"kernelspec": {"display_name": "venv", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.12.5"}}, "nbformat": 4, "nbformat_minor": 5}