{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# Imbalanced data sets\n", "\n", "One way bias may get introduced into your model is if your data is imbalanced. Let's use the [adult income dataset](https://raw.githubusercontent.com/jbrownlee/Datasets/master/adult-all.csv) (pre-download in the files-folder).\n", "\n", "We'll be using [this](https://machinelearningmastery.com/imbalanced-classification-with-the-adult-income-dataset/) example.\n", "\n", "\n", "https://github.com/Trusted-AI/AIF360\n", "\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Import data\n", "First, import the data. We use read_csv from pandas to create a dataframe, drop the rows containing NA and visualize the imbalance in the dataset."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# load and summarize the dataset\n", "from pandas import read_csv\n", "from collections import Counter\n", "# define the dataset location\n", "filename = 'files/adult-all.csv'\n", "# load the csv file as a data frame\n", "df = read_csv(filename, header=None, na_values='?')\n", "# drop rows with missing\n", "df = df.dropna()\n", "# summarize the shape of the dataset\n", "print(df.shape)\n", "# summarize the class distribution\n", "target = df.values[:,-1]\n", "counter = Counter(target)\n", "for k,v in counter.items():\n", " per = v / len(target) * 100\n", " print('Class=%s, Count=%d, Percentage=%.3f%%' % (k, v, per))"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Next up, let's take all the numerical fields and graph them in boxplots. Some are distributed in a normal fashion, others more randomly.\n", "\n", "You should notice however the enormous difference in scale: Variable 2 is always below 1.5, variable 10 goes up to 100.000. This we can solve using scaling."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from matplotlib import pyplot\n", "\n", "# select columns with numerical data types\n", "num_ix = df.select_dtypes(include=['int64', 'float64']).columns\n", "# select a subset of the dataframe with the chosen columns\n", "subset = df[num_ix]\n", "# create a histogram plot of each numeric variable\n", "subset.hist()\n", "pyplot.show()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Model Test and Baseline Result\n", "\n", "As the code online states:\n", "We will evaluate candidate models using repeated stratified k-fold cross-validation.\n", "\n", "The k-fold cross-validation procedure provides a good general estimate of model performance that is not too optimistically biased, at least compared to a single train-test split. We will use k=10, meaning each fold will contain about 45,222/10, or about 4,522 examples.\n", "\n", "Stratified means that each fold will contain the same mixture of examples by class, that is about 75 percent to 25 percent for the majority and minority classes respectively. Repeated means that the evaluation process will be performed multiple times to help avoid fluke results and better capture the variance of the chosen model. We will use three repeats.\n", "\n", "This means a single model will be fit and evaluated 10 * 3 or 30 times and the mean and standard deviation of these runs will be reported.\n", "\n", "This can be achieved using the RepeatedStratifiedKFold scikit-learn class.\n", "\n", "We will predict a class label for each example and measure model performance using classification accuracy.\n", "\n", "The evaluate_model() function below will take the loaded dataset and a defined model and will evaluate it using repeated stratified k-fold cross-validation, then return a list of accuracy scores that can later be summarized.\n", "\n", "Which comes down to:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# test harness and baseline model evaluation for the adult dataset\n", "from collections import Counter\n", "from numpy import mean\n", "from numpy import std\n", "from numpy import hstack\n", "from pandas import read_csv\n", "from sklearn.preprocessing import LabelEncoder\n", "from sklearn.model_selection import cross_val_score\n", "from sklearn.model_selection import RepeatedStratifiedKFold\n", "from sklearn.dummy import DummyClassifier\n", " \n", "# load the dataset\n", "def load_dataset(full_path):\n", " # load the dataset as a numpy array\n", " dataframe = read_csv(full_path, header=None, na_values='?')\n", " # drop rows with missing\n", " dataframe = dataframe.dropna()\n", " # split into inputs and outputs\n", " last_ix = len(dataframe.columns) - 1\n", " X, y = dataframe.drop(last_ix, axis=1), dataframe[last_ix]\n", " # select categorical and numerical features\n", " cat_ix = X.select_dtypes(include=['object', 'bool']).columns\n", " num_ix = X.select_dtypes(include=['int64', 'float64']).columns\n", " # label encode the target variable to have the classes 0 and 1\n", " y = LabelEncoder().fit_transform(y)\n", " return X.values, y, cat_ix, num_ix\n", " \n", "# evaluate a model\n", "def evaluate_model(X, y, model):\n", " # define evaluation procedure\n", " cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n", " # evaluate model\n", " scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n", " return scores\n", " \n", "# define the location of the dataset\n", "full_path = 'files/adult-all.csv'\n", "# load the dataset\n", "X, y, cat_ix, num_ix = load_dataset(full_path)\n", "# summarize the loaded dataset\n", "print(X.shape, y.shape, Counter(y))\n", "# define the reference model\n", "model = DummyClassifier(strategy='most_frequent')\n", "# evaluate the model\n", "scores = evaluate_model(X, y, model)\n", "# summarize performance\n", "print('Mean Accuracy: %.3f (%.3f)' % (mean(scores), std(scores)))"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Evaluate models\n", "\n", "Finally, the codes applies a number of different models to the dataset and compares the result.\n", "\n", "Warning: the next code block will take a long time to run."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# spot check machine learning algorithms on the adult imbalanced dataset\n", "from matplotlib import pyplot\n", "from sklearn.preprocessing import OneHotEncoder\n", "from sklearn.preprocessing import MinMaxScaler\n", "from sklearn.pipeline import Pipeline\n", "from sklearn.compose import ColumnTransformer\n", "from sklearn.tree import DecisionTreeClassifier\n", "from sklearn.svm import SVC\n", "from sklearn.ensemble import RandomForestClassifier\n", "from sklearn.ensemble import GradientBoostingClassifier\n", "from sklearn.ensemble import BaggingClassifier\n", "\n", " \n", "# define models to test\n", "def get_models():\n", " models, names = list(), list()\n", " # CART\n", " models.append(DecisionTreeClassifier())\n", " names.append('CART')\n", " # SVM\n", " models.append(SVC(gamma='scale'))\n", " names.append('SVM')\n", " # Bagging\n", " models.append(BaggingClassifier(n_estimators=100))\n", " names.append('BAG')\n", " # RF\n", " models.append(RandomForestClassifier(n_estimators=100))\n", " names.append('RF')\n", " # GBM\n", " models.append(GradientBoostingClassifier(n_estimators=100))\n", " names.append('GBM')\n", " return models, names\n", " \n", "# define the location of the dataset\n", "full_path = 'files/adult-all.csv'\n", "# load the dataset\n", "X, y, cat_ix, num_ix = load_dataset(full_path)\n", "# define models\n", "models, names = get_models()\n", "results = list()\n", "# evaluate each model\n", "for i in range(len(models)):\n", " # define steps\n", " steps = [('c',OneHotEncoder(handle_unknown='ignore'),cat_ix), ('n',MinMaxScaler(),num_ix)]\n", " # one hot encode categorical, normalize numerical\n", " ct = ColumnTransformer(steps)\n", " # wrap the model i a pipeline\n", " pipeline = Pipeline(steps=[('t',ct),('m',models[i])])\n", " # evaluate the model and store results\n", " scores = evaluate_model(X, y, pipeline)\n", " results.append(scores)\n", " # summarize performance\n", " print('>%s %.3f (%.3f)' % (names[i], mean(scores), std(scores)))\n", "# plot the results\n", "pyplot.boxplot(results, labels=names, showmeans=True)\n", "pyplot.show()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["This exercises did not contain any actual exercises. The code was too heavy to reasonably expect you to write it yourself now. Make sure you understand it though, as it does contain a number of interesting points."]}], "metadata": {"kernelspec": {"display_name": "venv", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.12.5"}}, "nbformat": 4, "nbformat_minor": 2}