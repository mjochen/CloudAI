{"cells": [{"cell_type": "markdown", "id": "74e43080", "metadata": {}, "source": ["# Outlier detection in the forest-dataset.\n", "\n", "We'll be using the [covertype](https://scikit-learn.org/stable/datasets/real_world.html#covtype-dataset) dataset from sklearn for this example."]}, {"cell_type": "markdown", "id": "1639d55a", "metadata": {}, "source": ["## Load data\n", "\n", "First load the data!"]}, {"cell_type": "code", "execution_count": null, "id": "740b1da0", "metadata": {}, "outputs": [], "source": ["# !pip install scikit-learn"]}, {"cell_type": "code", "execution_count": null, "id": "d43a46ad", "metadata": {}, "outputs": [], "source": ["from sklearn.datasets import fetch_covtype\n", "\n", "# Load the Covertype dataset\n", "data = fetch_covtype(as_frame=True)\n", "X = data.data\n", "y = data.target\n", "\n", "print(X.head())\n", "print(y.head())"]}, {"cell_type": "markdown", "id": "a6bdc463", "metadata": {}, "source": ["This dataset is pretty large. Not only in rows, 500k, but also in dimensionality (nr of columns): 54. It'll allow us to do some serious searching and cleaning. (The \"head\"-output is also not very pretty because of that).\n", "\n", "SKlearn was really nice in giving us the data pre-split, with X and Y separately. But we want to work with outliers, meaning we'll probably delete rows at some point. Then it'll be better to have one dataframe with both X and y, where the y-column is called \"target\". We can still split them later on.\n", "\n", "(It also has the added advantage that we can randomly delete rows in \"df\" and restore them by copying \"X\" and \"y\" again.)"]}, {"cell_type": "code", "execution_count": null, "id": "94bf53ba", "metadata": {}, "outputs": [], "source": ["# Up to you!\n", "\n"]}, {"cell_type": "markdown", "id": "a12647c1", "metadata": {}, "source": ["## Data exploration\n", "\n", "Always start with exploration. First, get the info on X."]}, {"cell_type": "code", "execution_count": null, "id": "b9719dc7", "metadata": {}, "outputs": [], "source": ["# Up to you!\n", "\n"]}, {"cell_type": "markdown", "id": "24a4265e", "metadata": {}, "source": ["53 fields, all float64 (good for models!) and no null-values. Promising. But what graphs works best to see if any outliers are present? The boxplot. Everything outside of the whiskers is outside of 3*IQR and can safely be deleted."]}, {"cell_type": "code", "execution_count": null, "id": "dda01e31", "metadata": {}, "outputs": [], "source": ["# Up to you!\n", "\n"]}, {"cell_type": "markdown", "id": "d7358ab8", "metadata": {}, "source": ["The first couple of fields look normal, bet when starting with the soil types it's obvious that something is going on.\n", "\n", "![](../files/2025-05-12-21-09-12.png)\n", "\n", "This graphs shows all values are around 0, but there is one values (or maybe a couple of values, but not a lot of them) that is 1 and these mess up our graph. With any luck it's the same (couple of) row(s) that have these values.\n", "\n", "Show all rows that have a value of 1 in \"soil_30\"."]}, {"cell_type": "code", "execution_count": null, "id": "1940d8ce", "metadata": {}, "outputs": [], "source": ["# Up to you!\n", "\n"]}, {"cell_type": "markdown", "id": "101358f1", "metadata": {}, "source": ["No luck. But strangely enough the other soils are all \"0\". And we said the other values were around 0, but they could have also been exactly 0.\n", "\n", "How many different values are stored in the soil-columns (and the other columns)?"]}, {"cell_type": "code", "execution_count": null, "id": "72927ec6", "metadata": {}, "outputs": [], "source": ["# Up to you!\n", "\n"]}, {"cell_type": "markdown", "id": "70b99f34", "metadata": {}, "source": ["Found it! \"Wilderniss area\" and \"soil\" are simply 1 or 0. We won't find any outliers there. Let's refocus our attention to the other columns and draw the box_plots again.\n", "\n", "Draw box plots for the first 10 columns."]}, {"cell_type": "code", "execution_count": null, "id": "4683de26", "metadata": {}, "outputs": [], "source": ["# Up to you!\n", "\n"]}, {"cell_type": "markdown", "id": "c89577d5", "metadata": {}, "source": ["Aspect is fine (some skewing, tail to the right) but the others all have outliers."]}, {"cell_type": "markdown", "id": "3ecc54d6", "metadata": {}, "source": ["## Dealing with outliers\n", "\n", "Deleting all rows with outliers is one option, but not always the best. It has it's downsides:\n", "\n", "The outliers can be informative: There are some patches of wood where very special trees grow. These only grow on places where there is no (or very little) Hillshade_9am. By deleting the outliers in that column, we'll be deleting the entire type of tree.\n", "\n", "**You risk introducing bias**: by deleting all data where the horizontal_distance_to_fire_points is large, you deleted all the information in that category. That means that you've now chopped a specific part of your dataset of. And chopping of a part is bad, but chopping of one particular part is really bad.\n", "\n", "So how bad is simply deleting all outliers? Go over the first ten columns and delete all outliers, printing the amount of rows you've deleted."]}, {"cell_type": "code", "execution_count": null, "id": "94a89f0a", "metadata": {}, "outputs": [], "source": ["# Up to you!\n", "\n"]}, {"cell_type": "markdown", "id": "d29ffc62", "metadata": {}, "source": ["\"Vertical_Distance_To_Hydrology\" is responsible for deleting 5157 rows. That is a lot, even in 500k rows. (About 1%, in fact.) And our count isn't fair because \"Horizontal_Distance_To_Roadways\" doesn't seem to have outliers, but they had but they were already deleted by deleting all the \"Vertical_Distance_To_Hydrology\".\n", "\n", "First run the next cell to restore the data, and then count the amount of rows deleting the outliers would delete (without actually deleting them)."]}, {"cell_type": "code", "execution_count": null, "id": "0209c1e9", "metadata": {}, "outputs": [], "source": ["# Run to restore the data\n", "df = X.copy()\n", "df['target'] = y"]}, {"cell_type": "code", "execution_count": null, "id": "3bf3e8ae", "metadata": {}, "outputs": [], "source": ["# Up to you!\n", "\n"]}, {"cell_type": "markdown", "id": "09c97436", "metadata": {}, "source": ["Another question we should be asking ourselves: suppose we delete all the outliers, what kind of damage are we inflicting on our output labels? If we delete the outliers, are we deleting rows from all output classes equally or are we targeting one class in particular?\n", "\n", "Store the number of rows per class (value_counts in the target-column). Then delete the outliers and store the result again."]}, {"cell_type": "code", "execution_count": null, "id": "d5895ea7", "metadata": {}, "outputs": [], "source": ["# Up to you!\n", "\n"]}, {"cell_type": "markdown", "id": "8f0ea89f", "metadata": {}, "source": ["Merge both value_counts and show the percentage decline."]}, {"cell_type": "code", "execution_count": null, "id": "9ffdc3b3", "metadata": {}, "outputs": [], "source": ["import pandas as pd\n", "# Merge pre_class_counts and post_class_counts into a DataFrame\n", "class_counts_comparison = pd.DataFrame({\n", "    'Before': pre_class_counts,\n", "    'After': post_class_counts\n", "})\n", "\n", "# Calculate the percentage decrease\n", "class_counts_comparison['Percentage Decrease'] = ((class_counts_comparison['Before'] - class_counts_comparison['After']) / class_counts_comparison['Before']) * 100\n", "\n", "print(class_counts_comparison)"]}, {"cell_type": "markdown", "id": "88566ec2", "metadata": {}, "source": ["Doable for most classes, but if you want valid prediction ons class 7 this is not the way to go forward. If this is your goal you should now start looking at models that can handle outliers well (like tree-based models).\n", "\n", "You could also try other methods of dealing with outliers (as we will be doing), but remember that we're actively interfering with our data. There is a line between \"helping\" and \"going over the line\" that is very easy to cross (as anyone with a mother in law can tell you, or so I've heard). When you clip the data you're clipping these rows, 4.4% of class 7, same goes for scaling.\n", "\n", "But we have an advantage! We can train many, many models (unlike the folks doing large language models). So maybe try a model with the outliers and another without?"]}, {"cell_type": "markdown", "id": "7334a53c", "metadata": {}, "source": ["## Windsorization\n", "\n", "New plan: we delete everything out of 4\\*IQR (way out of bounds) and clip all values above 3\\*IQR to 3\\*IQR. This way we save most values (or so we think) and get rid of the pesky remaining outliers.\n", "\n", "First, delete rows outside of 4*IQR. (And remember to restore the data before starting here.)"]}, {"cell_type": "code", "execution_count": null, "id": "89651b3f", "metadata": {}, "outputs": [], "source": ["# Up to you!\n", "\n"]}, {"cell_type": "markdown", "id": "7b541005", "metadata": {}, "source": ["If you stored the values you would have noticed we deleted 1.46% of class 7. The rest is all below 0.4%. Next up is clipping. Let's clip the values at 20% and 80%. That way we still keep some outliers, but the data is better in check."]}, {"cell_type": "code", "execution_count": null, "id": "8e4e52b4", "metadata": {}, "outputs": [], "source": ["# Up to you!\n", "\n"]}, {"cell_type": "markdown", "id": "c783a704", "metadata": {}, "source": ["We can't see the result anymore by showing the value_counts because we never deleted rows. The only way of showing the results is by doing the box-plots again. In fact, we have X (the original data) and df (the new data). But them next to each other in the same graph!"]}, {"cell_type": "code", "execution_count": null, "id": "cec0f225", "metadata": {}, "outputs": [], "source": ["# Up to you!\n", "\n"]}, {"cell_type": "markdown", "id": "90763574", "metadata": {}, "source": ["The whiskers have grown shorter. This is normal, but it does show an important effect. Let's focus on 2 columns, Vertical_Distance_To_Hydrology and Horizontal_Distance_To_Roadways. We'll start with the first, plotting the values from X and df in a histogram together."]}, {"cell_type": "code", "execution_count": null, "id": "6f6bc934", "metadata": {}, "outputs": [], "source": ["import matplotlib.pyplot as plt\n", "\n", "# Plot histogram for \"Vertical_Distance_To_Hydrology\" from X and df\n", "plt.figure(figsize=(10, 6))\n", "bin_size = 10\n", "min_value = min(X[\"Vertical_Distance_To_Hydrology\"].min(), df[\"Vertical_Distance_To_Hydrology\"].min())\n", "max_value = max(X[\"Vertical_Distance_To_Hydrology\"].max(), df[\"Vertical_Distance_To_Hydrology\"].max())\n", "bins = range(int(min_value), int(max_value) + bin_size, bin_size)\n", "\n", "plt.hist(X[\"Vertical_Distance_To_Hydrology\"], bins=bins, alpha=0.5, label=\"Original Data (X)\", color='blue')\n", "plt.hist(df[\"Vertical_Distance_To_Hydrology\"], bins=bins, alpha=0.5, label=\"Modified Data (df)\", color='orange')\n", "\n", "# Add labels, title, and legend\n", "plt.xlabel(\"Vertical_Distance_To_Hydrology\")\n", "plt.ylabel(\"Frequency\")\n", "plt.title(\"Histogram of Vertical_Distance_To_Hydrology\")\n", "plt.legend()\n", "\n", "# Show the plot\n", "plt.show()"]}, {"cell_type": "markdown", "id": "909a43cd", "metadata": {}, "source": ["And now Horizontal_Distance_To_Roadways."]}, {"cell_type": "code", "execution_count": null, "id": "40857d71", "metadata": {}, "outputs": [], "source": ["import matplotlib.pyplot as plt\n", "\n", "# Plot histogram for \"Horizontal_Distance_To_Roadways\" from X and df\n", "plt.figure(figsize=(10, 6))\n", "bin_size = 100\n", "min_value = min(X[\"Horizontal_Distance_To_Roadways\"].min(), df[\"Horizontal_Distance_To_Roadways\"].min())\n", "max_value = max(X[\"Horizontal_Distance_To_Roadways\"].max(), df[\"Horizontal_Distance_To_Roadways\"].max())\n", "bins = range(int(min_value), int(max_value) + bin_size, bin_size)\n", "\n", "plt.hist(X[\"Horizontal_Distance_To_Roadways\"], bins=bins, alpha=0.5, label=\"Original Data (X)\", color='blue')\n", "plt.hist(df[\"Horizontal_Distance_To_Roadways\"], bins=bins, alpha=0.5, label=\"Modified Data (df)\", color='orange')\n", "\n", "# Add labels, title, and legend\n", "plt.xlabel(\"Horizontal_Distance_To_Roadways\")\n", "plt.ylabel(\"Frequency\")\n", "plt.title(\"Histogram of Horizontal_Distance_To_Roadways\")\n", "plt.legend()\n", "\n", "# Show the plot\n", "plt.show()"]}, {"cell_type": "markdown", "id": "a6f16a4a", "metadata": {}, "source": ["These fields were chosen because the first lost a lot of data to 3\\*IQR, the second because it lost none. But the effect of clipping is very obvious: we're introducing giant spikes at the end of the orange spectrum. That means we've been clipping way to aggressively. There shouldn't be any visible spikes here. In fact, the guidelines are:\n", "\n", "| Percentile range | Portion modified | Correct description     |\n", "| ---------------- | ---------------- | ----------------------- |\n", "| 0.5%\u00e2\u20ac\u201c99.5%       | 1%               | Conservative            |\n", "| 1%\u00e2\u20ac\u201c99%           | 2%               | Mild                    |\n", "| 2.5%\u00e2\u20ac\u201c97.5%       | 5%               | Moderate/Aggressive     |\n", "| 5%\u00e2\u20ac\u201c95%           | 10%              | Very aggressive         |\n", "\n", "\n", "Let's try again with the conservative .5% without deleting the extremes first."]}, {"cell_type": "code", "execution_count": null, "id": "0d5702e7", "metadata": {}, "outputs": [], "source": ["# Up to you!\n", "\n"]}, {"cell_type": "markdown", "id": "84256198", "metadata": {}, "source": ["And the graph for Vertical_Distance_To_Hydrology?"]}, {"cell_type": "code", "execution_count": null, "id": "50866bc2", "metadata": {}, "outputs": [], "source": ["import matplotlib.pyplot as plt\n", "\n", "# Plot histogram for \"Vertical_Distance_To_Hydrology\" from X and df\n", "plt.figure(figsize=(10, 6))\n", "bin_size = 10\n", "min_value = min(X[\"Vertical_Distance_To_Hydrology\"].min(), df[\"Vertical_Distance_To_Hydrology\"].min())\n", "max_value = max(X[\"Vertical_Distance_To_Hydrology\"].max(), df[\"Vertical_Distance_To_Hydrology\"].max())\n", "bins = range(int(min_value), int(max_value) + bin_size, bin_size)\n", "\n", "plt.hist(X[\"Vertical_Distance_To_Hydrology\"], bins=bins, alpha=0.5, label=\"Original Data (X)\", color='blue')\n", "plt.hist(df[\"Vertical_Distance_To_Hydrology\"], bins=bins, alpha=0.5, label=\"Modified Data (df)\", color='orange')\n", "\n", "# Add labels, title, and legend\n", "plt.xlabel(\"Vertical_Distance_To_Hydrology\")\n", "plt.ylabel(\"Frequency\")\n", "plt.title(\"Histogram of Vertical_Distance_To_Hydrology\")\n", "plt.legend()\n", "\n", "# Show the plot\n", "plt.show()"]}, {"cell_type": "markdown", "id": "3a55c8fa", "metadata": {}, "source": ["Way better. Still some spikes, but at the very least they're not higher than the data anymore. The other graph?"]}, {"cell_type": "code", "execution_count": null, "id": "9a33eb60", "metadata": {}, "outputs": [], "source": ["import matplotlib.pyplot as plt\n", "\n", "# Plot histogram for \"Horizontal_Distance_To_Roadways\" from X and df\n", "plt.figure(figsize=(10, 6))\n", "bin_size = 100\n", "min_value = min(X[\"Horizontal_Distance_To_Roadways\"].min(), df[\"Horizontal_Distance_To_Roadways\"].min())\n", "max_value = max(X[\"Horizontal_Distance_To_Roadways\"].max(), df[\"Horizontal_Distance_To_Roadways\"].max())\n", "bins = range(int(min_value), int(max_value) + bin_size, bin_size)\n", "\n", "plt.hist(X[\"Horizontal_Distance_To_Roadways\"], bins=bins, alpha=0.5, label=\"Original Data (X)\", color='blue')\n", "plt.hist(df[\"Horizontal_Distance_To_Roadways\"], bins=bins, alpha=0.5, label=\"Modified Data (df)\", color='orange')\n", "\n", "# Add labels, title, and legend\n", "plt.xlabel(\"Horizontal_Distance_To_Roadways\")\n", "plt.ylabel(\"Frequency\")\n", "plt.title(\"Histogram of Horizontal_Distance_To_Roadways\")\n", "plt.legend()\n", "\n", "# Show the plot\n", "plt.show()"]}, {"cell_type": "markdown", "id": "e57fcc31", "metadata": {}, "source": ["So to conclude: when clipping (or doing winsorzation), keep it chill."]}], "metadata": {"kernelspec": {"display_name": "venv (3.12.5)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.12.5"}}, "nbformat": 4, "nbformat_minor": 5}